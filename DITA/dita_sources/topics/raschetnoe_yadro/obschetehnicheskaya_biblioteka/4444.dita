<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_x5n_gv5_qf">
  <title>Оптимизация параметров модели</title>
  <body>
    <table id="table_x4b_zsz_qy">
      <tgroup cols="2">
        <colspec colnum="1" colname="col1"/>
        <colspec colnum="2" colname="col2"/>
        <tbody>
          <row>
            <entry><image href="images_old/4444.png" height="32" width="32" id="image_y4b_zsz_qy"
              /></entry>
            <entry>Оптимизация параметров модели</entry>
          </row>
          <row>
            <entry>в палитре</entry>
            <entry/>
          </row>
          <row>
            <entry><image href="images_old/4444s.png" height="54" width="101" id="image_z4b_zsz_qy"
              /></entry>
            <entry/>
          </row>
          <row>
            <entry>на схеме</entry>
            <entry/>
          </row>
          <row>
            <entry namest="col1" nameend="col2">
              <p>Блок оптимизации параметров модели предназначен для подбора таких <b>параметров
                  оптимизации</b>, которые бы удовлетворяли необходимым значениям <b>критериев
                  оптимизации</b>.</p>
              <p><b>Свойства</b> блока оптимизации:</p>
              <p><b>Режим оптимизации параметров</b> — оптимизация осуществляется либо динамически в
                течение одного цикла моделирования системы, изменяя параметр оптимизации прямо в
                ходе моделирования, либо по полному переходному процессу системы с помощью серии
                последовательных циклов моделирования, в каждом из которых обновляется значение
                оптимизируемого параметра.</p>
              <p><b>Периодично анализа критериев оптимизации при расчете в динамике, сек </b>— как
                часто в ходе моделирования будет происходить анализ критериев и следовательно
                изменение значения оптимизируемого параметра. Опция имеет смысл только при
                установленном динамическом режиме оптимизации параметров.</p>
              <p><b>Начальные приближения выходов блока</b> — начальные значения оптимизируемых
                параметров с которых начинается расчет.</p>
              <p><b>Минимальные значения выходов блока </b>— показывает минимальные значения,
                которые могут принимать оптимизируемые параметры.</p>
              <p><b>Максимальные значения выходов блока </b>— показывает максимальные значения,
                которые могут принимать оптимизируемые параметры.</p>
              <p><b>Абсолютная точность подбора значений выходов</b> — минимальный щаг, с которым
                могут изменяться выходные величины.</p>
              <p><b>Начальные приращения значений выходов</b> — величина изменения значений выходов
                на первом шаге подбора.</p>
              <p><b>Минимальные значения входных критериев оптимизации </b>— нижняя граница целевого
                диапазона критериев оптимизации. Задается в виде линейного массива, если критериев
                больше одного.</p>
              <p><b>Максимальные значения входных критериев оптимизации</b> — верхняя граница
                целевого диапазона критериев оптимизации. Задается в виде линейного массива, если
                критериев больше одного.</p>
              <p><b>Тип суммарного критерия оптимизации</b> — метод свертывания критериев, для
                формирования целевой функции. </p>
              <p><b>Метод оптимизации</b> — используемый численный метод оптимизации.</p>
              <p><b>Максимальное количество повторных моделирований при расчете по полному
                  переходному процессу </b>— максимальное число повторных моделирований в ходе
                которых алгоритм будет пытаться подобрать оптимальные параметры. Если по окончании
                указанного числа расчетов, не были найдены значения параметров, удовлетворяющие
                критериям оптимизации, то расчет прерывается. Опция применима только если выбран
                режим оптимизации «По полному переходному процессу»</p>
              <p><b>Количество серий случайных испытаний для стохастического метода</b> - </p>
              <p><b>Количество случайных испытаний в одной серии для стохастического метода</b> - </p>
              <p><b>Выдача информации о процессе оптимизации</b> — включение опции означает выдачу
                информационных сообщений о значении параметров и критериев оптимизации после каждого
                их изменения в процессе расчета системы.</p>
              <p><b>Параметры оптимизации</b> или оптимизируемые параметры — это независимые
                величины, значение которых подбирается блоком на основании существующих численных
                методов оптимизации, с целью соответствия определенных критериев оптимизации своим
                целевым значениям.</p>
              <p><b>Критерии оптимизации</b> — избранные величины, к диапазону значений которых
                предъявляются определенные требования, и на значения которых прямо или косвенно
                влияют значения параметров оптимизации.</p>
              <p>Таким образом, задачу оптимизации можно сформулировать, как нахождение вектора
                параметров оптимизации, при которых критерии качества удовлетворяют своим
                ограничениям.</p>
              <p>Задача оптимизации плохо поддается формализации, поэтому для получения сколь-нибудь
                эффективных ее результатов, множество критериев и параметров оптимизации, имеющих
                разную физическую природу и диапазоны изменения, должны быть масштабированы и
                переведены к нормированным величинам.</p>
              <p>При наличии множества критериев, для формализации условия задачи оптимизации,
                обычно переходят от нескольких частных критериев q1, …, qm к одному общему критерию,
                который формируется в виде функции частных критериев.Такую процедуру называют
                свертыванием критериев. В результате получаем общий критерий (целевую функцию)</p>
              <p>f(<b>x</b>) = j (q1(<b>x</b>), ... , qm(<b>x</b>) )</p>
              <p>в виде функции от оптимизируемых параметров. Решение задачи многокритериальной
                оптимизации сводится к минимизации этого критерия. Один из наиболее часто
                используемых способов свертывания частных критериев — средний степенной критерий
                оптимальности. Именно он используется для свертывания критериев оптимизации в
                SimInTech:</p>
              <p><image href="images_old/4444_html_67d54a96.gif" height="57" width="218" id="image_apb_zsz_qy"
                /></p>
              <p>При p=1 получим аддитивный критерий</p>
              <p><image href="images_old/4444_html_m6f47db3b.gif" height="50" width="180" id="image_bpb_zsz_qy"
                /></p>
              <p>При p=2 получим квадратичный критерий</p>
              <p><image href="images_old/4444_html_m389f20df.gif" height="57" width="213" id="image_cpb_zsz_qy"
                /></p>
              <p>При p, стремящемся к бесконечности, общий критерий сводится к наибольшему из
                нормированных частных критериев (минимаксный критерий)</p>
              <p><image href="images_old/4444_html_27d4fa79.gif" height="23" width="239" id="image_dpb_zsz_qy"
                /></p>
              <p>При p=0, логарифмируя выражение общего критерия и переходя к пределу по p,
                стремящемуся к нулю, после применения правила Лопиталя получаем средний
                геометрический (мультипликативный) критерий оптимальности.</p>
              <p><image href="images_old/4444_html_7819d6e3.gif" height="57" width="197" id="image_epb_zsz_qy"
                /></p>
              <p>Получив обобщенный критерий, можно приступать к решению задачи оптимизации. В
                SimInTech реализованы 3 наиболее подходящих для программной реализации алгоритма
                оптимизации, в которых решение о переходе в новую точку поиска принимается на
                основании сравнения значений критерия в двух точках.</p>
              <p><b>Алгоритм Поиск-2</b></p>
              <p>Реализуется алгоритм деления шага пополам при одном оптимизируемом параметре (n =
                1) и алгоритм преобразований матрицы направлений при n >1. Далее рассматривается
                алгоритм многомерного поиска.</p>
              <p>Направления поиска на k-том этапе задаются матрицей Sk. На очередном этапе
                производится серия спусков в направлениях векторов s1,...,sn, представляющих собой
                столбцы матрицы Sk . Векторы перемещений на каждом из спусков равны соответственно
                g₁s₁, ..., gnsn .. После выполнения спусков матрица направлений преобразуется по
                формуле</p>
              <p>Sk+1 = SkΛkPk</p>
              <p>где Λk - диагональная матрица, элементы которой равны λk = γi, если γi ≠0, и λk =
                0.5, если γi = 0; Pk - ортогональная матрица. Умножение на ортогональную матрицу
                необходимо для изменения набора направлений поиска. Если на всех этапах Pk = I , то
                направления поиска не изменяются от этапа к этапу и мы имеем алгоритм
                покоординатного спуска. Очевидно, что выбор матриц Pk существенно влияет на
                эффективность поиска. </p>
              <p>Было испытано несколько различных способов выбора ортогональных матриц Pk , в том
                числе и случайный выбор. Лучшим оказался способ, при котором все матрицы Pk равны
                между собой и определяются в виде</p>
              <p><image href="images_old/4444_html_ce6ad88.gif" height="235" width="369" id="image_fpb_zsz_qy"
                />*</p>
              <p>Рассмотрим этапы алгоритма в многомерном случае.</p>
              <ol id="ol_gpb_zsz_qy">
                <li>
                  <p>Начальная матрица направлений задается диагональной с элементами на главной
                    диагонали, равными начальным приращениям по параметрам.</p>
                </li>
                <li>
                  <p>Выполнить цикл для i=1, …, n:</p>
                  <p>2.1 Выполнить пробный щаг в направлении si:</p>
                  <p>y=x+si</p>
                  <p>Если этот шаг удачный (f(y)&lt;f(x)), перейти к пункту 2.3.</p>
                  <p>2.2 Выполнить пробный шаг в противоположном направлении:</p>
                  <p>y=x-si</p>
                  <p>Если оба пробных шага оказались неудачными, принять λ=0.5 и перейти к пункту
                    2.4</p>
                  <p>2.3 Выполнить спуск в выбранном направлении, в результате получим новую точку
                    поиска</p>
                  <p>x=x+γsi, принять λ=|γ|</p>
                  <p>2.4 Принять si= λsi. Перейти к следующему значению счетчика цикла либо выйти из
                    цикла (если i=n).</p>
                </li>
                <li>
                  <p>Умножить матрицу направлений S на ортогональную матрицу P, задаваемую
                    выражением (*).</p>
                </li>
                <li>
                  <p>При выполнении условия окончания поиска завершить работу алгоритма, в противном
                    случае — перейти к п.2 с новыми значениями вектора x и матрицы S.</p>
                </li>
              </ol>
              <p>Поиск прекращается при выполнении одного из следующих условий:</p>
              <p>-целевая функция достигла минимума (все требования выполняются);</p>
              <p>-превышено заданное число вычислений целевой функции;</p>
              <p>-приращения по каждому из параметров стали меньше заданного значения;</p>
              <p>-принудительный останов.</p>
              <p><b>Алгоритм Поиск-4</b></p>
              <p>Реализуется алгоритм квадратичной интерполяции при одном оптимизируемом параметре
                (n = 1) и алгоритм преобразований вращения и растяжения-сжатия (n >1).</p>
              <p>Рассмотрим алгоритм при n > 1. Он основан на выполнении преобразований растяжения -
                сжатия и преобразований вращения для такого преобразования системы координат, при
                котором матрица вторых производных (матрица Гессе) приближается к единичной, а
                направления поиска становятся сопряженными. Этот алгоритм использует квадратичную
                интерполяцию.</p>
              <p>Пусть H - симметричная положительно-определенная матрица. Будем строить
                последовательность матриц</p>
              <p>H0 = H, H1 ,..., Hk ,</p>
              <p>Каждая из которых получается из предыдущей путем выполнения следующего
                преобразования </p>
              <p>Hk= PkTΛkTHk-1ΛkPk</p>
              <p>где Λk - диагональная матрица с элементами λi = hii-1/2 (hii - диагональные
                элементы Hk-1); Pk - ортогональная матрица. После умножения матрицы Hk-1 слева и
                справа на Λk получаем матрицу с единичными диагональными элементами. Можно
                надеяться, что при подходящем выборе ортогональных матриц Pk матрица Hk будет
                стремиться к единичной. На этом, в частности, основан метод вращений для расчета
                собственных значений симметричных матриц.</p>
              <p>Рассмотрим задачу поиска минимума функции нескольких переменных. На k-м этапе
                поиска поочередно минимизируется функция в направлениях векторов s1 ,...,sn,
                представляющих собой столбцы матрицы Sk. Для нахождения точки минимума в направлении
                si используется квадратичная интерполяция по трем равноотстоящим точкам </p>
              <p>z = x - asi, x , y=x + asi.</p>
              <p>Одновременно для каждого направления вычисляется</p>
              <p>λi = a(f(y) + f(z)-2f(x))-1/2 (**)</p>
              <p>После выполнения серии спусков матрица S преобразуется по формуле </p>
              <p>Sk+1 = SkΛk Pk ,</p>
              <p>где Λk - диагональная матрица, элементы которой определяются по (**); Pk -
                некоторая ортогональная матрица. Для квадратичной целевой функции матрица SkT H Sk ,
                где H - матрица Гессе, совпадает с матрицей Hk . Таким образом, при надлежащем
                выборе матриц Pk для квадратичной функции получаем SkT H Sk → I и направления поиска
                приближаются к сопряженным. В рассматриваемом алгоритме матрицы Pk одинаковы на всех
                этапах и определяются по формуле (*).</p>
              <p>Этапы работы алгоритма Поиск-4 аналогичны рассмотренным выше этапам алгоритма
                Поиск-2.</p>
              <p><b>Алгоритм Симплекс</b></p>
              <p>Используется метод «деформируемого многогранника» Недлера и Мида.</p>
              <p>В методе Нелдера-Мида минимизируется функция n независимых переменных с
                использованием n+1 вершин деформируемого многогранника. Каждая вершина может быть
                идентифицирована вектором x . Вершина (точка), в которой значение f(x) максимально,
                проектируется через центр тяжести (центроид) оставшихся вершин. Улучшенные (меньшие)
                значения целевой функции находятся последовательной заменой точки с максимальным
                значением f(x) на более “хорошие” точки, пока не будет найден минимум f(x).</p>
              <p>Далее кратко излагается суть алгоритма.</p>
              <p>Пусть xi(k) = [xi1(k),..., xij(k),..., xin(k)]T, i = 1,..., n+1, является i-й
                вершиной (точкой) на k-том этапе поиска, k = 0, 1,..., и пусть значение целевой
                функции в xi(k) равно f(xi(k)). Также отметим векторы многогранника, которые дают
                максимальное и минимальное значения.</p>
              <p>Определим </p>
              <p>f(xh(k)) = max{f(x1(k)),...,f(xn+1(k))}, </p>
              <p>где xh(k) = xi(k) , и </p>
              <p>f(xl(k)) = min{f(x1(k)),...,f(xn+1(k)), </p>
              <p>где xl(k) = xi(k) . </p>
              <p>Поскольку многогранник в En состоит из (n+1) вершин x1,...,xn+1, пусть xn+2 будет
                центром тяжести всех вершин, исключая xh.</p>
              <p>Тогда координаты этого центра определяются формулой</p>
              <p>xn+2,j(k)= (1/n)[(Sxij(k))-xhj(k)], i = 1,..., n+1; j =1,..., n;</p>
              <p>где индекс j обозначает координатное направление.</p>
              <p>Начальный симплекс обычно (не всегда) выбирается в виде регулярного симплекса,
                причем начало координат можно поместить в центр тяжести. Процедура отыскания вершины
                в En , в которой f(x) имеет лучшее значение, состоит из следующих операций.</p>
              <p><i>Отражение</i> - проектирование xh(k) через центр тяжести в соответствии с
                выражением </p>
              <p>xn+3(k) = xn+2(k)+a(xn+2(k)-xh(k)) (***)</p>
              <p>где a является коэффициентом отражения; xn+2(k) - центр тяжести, вычисляемый по
                формуле (***); xh(k) - вершина, в которой функция f(x) принимает наибольшее из n+1
                ее значений на k- том этапе.</p>
              <p>Растяжение. Эта операция состоит в следующем: если f(xn+3(k)) &lt;= f(xl(k)), то
                вектор(xn+3(k)-xn+2(k)) растягивается в соответствии с соотношением </p>
              <p>xn+4(k)= xn+2(k) +g(xn+3(k)-xn+2(k)),</p>
              <p>где g >1 представляет собой коэффициент растяжения. Если f(xn+4(k)) &lt;f(xl(k)) ,
                то xh(k) заменяется на xn+4(k) и процедура продолжается снова с операции 1 при k =
                k+1. В противном случае xh(k) заменяется на xn+3(k) и также осуществляется переход к
                операции 1 при k = k+1.</p>
              <p><i>Сжатие</i>. Если f(xn+3(k)) > f(xi(k)) для всех i &lt; > h , то вектор
                (xh(k)-xn+2(k)) сжимается в соответствии с формулой</p>
              <p>xn+5(k)= xn+2(k) +b(xh(k)-xn+2(k)), </p>
              <p>где 0 &lt; b &lt;1 представляет собой коэффициент сжатия. Затем xh(k) заменяем на
                xn+5(k) и возвращаемся к операции 1 для продолжения поиска на (k+1) шаге.</p>
              <p>Редукция. Если f(xn+5(k)) > f(xh(k)), все векторы (xi(k)-xl(k)), i = 1, ..., n +1,
                уменьшаются в 2 раза с отсчетом от xl(k) в соответствии с формулой</p>
              <p>xi(k) = xl(k) +0.5(xi(k)-xl(k)), i = 1, ..., n+1.</p>
              <p>Затем возвращаемся к операции 1 для продолжения поиска на (k + 1) шаге.</p>
              <p>Критерий окончания поиска- проверка условия</p>
              <p>{[1/(n+1)]S [f(xi(k))-f(xn+2(k))]2}1/2≤e ,</p>
              <p>где e - произвольное малое число, а f(xn+2(k)) - значение целевой функции в центре
                тяжести xn+2(k).</p>
              <p>На процесс оптимизации оказывают влияние коэффициенты отражения <b>a</b>,
                растяжения <b>g</b> и сжатия <b>b</b>. Коэффициент отражения <b>a</b> используется
                для проектирования вершины с наибольшим значением f(x) через центр тяжести
                деформируемого многогранника. Коэффициент <b>g</b> вводится для растяжения вектора
                поиска в случае, если отражение дает вершину со значением f(x) меньшим, чем
                наименьшее значение f(x), полученное до отражения. Коэффициент сжатия b используется
                для уменьшения вектора поиска, если операция отражения не привела к вершине со
                значением f(x), меньшим, чем второе по величине (после наибольшего) значение f(x),
                полученное до отражения. Таким образом, с помощью операций растяжения или сжатия
                размеры и форма деформируемого многогранника масштабируются так, чтобы они
                удовлетворяли топологии решаемой задачи.</p>
              <p>После того, как деформируемый многогранник подходящим образом масштабируется, его
                размеры должны поддерживаться неизменными, пока изменения в топологии задачи не
                потребуют применения многогранника другой формы. Анализ, проведенный Нелдером и
                Мидом, показал, что компромиссное значение a = 1. Ими также рекомендованы значения b
                = 0.5, g = 2. Более поздние исследования показали, что рекомендуются диапазоны
                0.4≤b≤ 0.6, 2.8 ≤g≤3.0, причем при 0&lt; b &lt; 0.4 существует вероятность того, что
                из-за уплощения многогранника будет иметь место преждевременное окончание процесса,
                а при b>0.6 может потребоваться большее число шагов для достижения окончательного
                решения.</p>
              <p><b>Работа с блоком оптимизации.</b></p>
              <p>На вход блока подается вектор критериев оптимизации. На основании их значений,
                используя численные методы оптимизации, происходит подбор значения вектора
                параметров оптимизации так, чтобы значения критериев лежали в необходимом
                диапазоне.</p>
              <p>Рассмотрим примеры использования блока оптимизации параметров модели. В пакет
                поставки SimInTech входит набор демонстрационных проектов, в том числе показывающих
                работу блока оптимизации. Проекты находятся по адресу
                  <b>C:\SimInTech\Demo\Automatic\Оптимизация</b></p>
              <p>Откроем проект <b>Оптимизация в динамике.</b><b>prt</b></p>
              <p>Синусоидальный сигнал подается на две системы — эталонную и настраиваемую. Далее
                вычитатель определяет сигнал рассогласования между системами и подает его на вход
                блока оптимизации, который, осуществляя сравнения сигнала рассогласования с его
                целевым значением, а также применяя методы численной оптимизации, генерирует на
                выходе некий корректирующий множитель, на который домножается сигнал настраиваемой
                системы с целью минимизации отклонения от эталонной. В данном случае параметром
                оптимизации является некий корректирующий коэффициент, а критерием оптимизации —
                величина рассогласования между выходами эталонной и настраиваиваемой системами. В
                ходе динамического расчета в течение одного цикла моделирования системы, блок
                оптимизации подбирает такой корректирующий коэффициент для настраиваемой системы,
                что сигнал рассогласования между эталонной и настраиваемой системами стремится к
                нулю.</p>
              <p>Второй пример <b>Оптимизация с повторениями расчётов.</b><b>prt </b>показывает
                работу блока в режиме повторения расчетов. </p>
              <p>В данном примере источник равномерного шума аналогично подается на две системы —
                некую эталонную и настраиваемую. Затем вычитатель формирует сигнал рассогласования,
                подаваемый на блок RMS, считающий среднеквадратичное отклонение сигнала
                рассогласования за один полный цикл расчета системы. Блок оптимизации рассчитывает
                корректирующий коэффициент, пытаясь минимизировать среднеквадратичное отклонение. В
                итоге, за несколько последовательных расчетов модели, сигнал рассогласования стал
                стремиться к нулю, и форма сигналов практически совпала.</p>
              <p>Таким образом системе понадобилось 5 последовательных расчетов, чтобы
                скорректировать сигнал настраиваемой системы так , чтобы он совпадал с
                эталонной.</p>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </body>
</topic>
